{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c11c9a4-769a-486d-9f30-37adfb64cf81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "from pandas.errors import DtypeWarning\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "warnings.simplefilter(action='ignore', category=DtypeWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3814b68d-36c0-464a-8c36-b03422e1481f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def idw_interpolation(known_coords, known_values, unknown_coords, power=2):\n",
    "    # 使用已知坐标创建cKDTree对象，以便高效查询最近的邻居\n",
    "    tree = cKDTree(known_coords)\n",
    "    \n",
    "    # 对每个未知点查询其k个最近的邻居，我们这里使用3个邻居\n",
    "    # distances存储到k个最近邻居的距离，indices存储k个最近邻居的索引\n",
    "    distances, indices = tree.query(unknown_coords, k=10)\n",
    "    \n",
    "    # 避免除以零的情况，如果距离为0，将其替换为一个非常小的数\n",
    "    distances[distances == 0] = 1e-10\n",
    "    \n",
    "    # 根据距离的倒数计算权重，权重与距离的倒数成比例\n",
    "    # power参数用于调整权重的影响，power越大，近处的点权重越大\n",
    "    weights = 1 / distances ** power\n",
    "    \n",
    "    # 对权重进行归一化，确保每个未知点的权重总和为1\n",
    "    weights /= weights.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # 使用权重和已知值计算插值值，采用加权平均的方式\n",
    "    # np.einsum用于执行权重与已知值的加权求和\n",
    "    # print(\"weights:\", weights)\n",
    "    # print(\"weights shape:\", weights.shape)\n",
    "    # print(\"known_values[indices]:\", known_values[indices])\n",
    "    # print(\"known_values[indices] shape:\", known_values[indices].shape)\n",
    "    interpolated_values = np.einsum('ij,ij->i', weights, known_values[indices])\n",
    "    \n",
    "    # 返回插值值\n",
    "    return interpolated_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa14f0cb-5f5e-4810-9882-d4518170e0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perform_idw(group, feature_name):\n",
    "    if feature_name =='ic':\n",
    "        group[feature_name] = pd.to_numeric(group[feature_name], errors='coerce')\n",
    "\n",
    "    known_coords = group[['lon_x', 'lat_x']].values  # 已知坐标（站点）\n",
    "    known_values = group[feature_name].values        # 已知值，使用传入的特性名称\n",
    "    \n",
    "    known_values = known_values.astype(float)\n",
    "    unknown_coords = group[['lon_y', 'lat_y']].drop_duplicates().values # 未知坐标（火点）\n",
    "    interpolated_values = idw_interpolation(known_coords, known_values, unknown_coords) # 执行IDW插值\n",
    "    \n",
    "    return pd.DataFrame({  # 返回插值结果\n",
    "        'date': group['date'].iloc[0],\n",
    "        'year': group['year_y'].iloc[0],\n",
    "        'month': group['month_y'].iloc[0],\n",
    "        'day': group['day_y'].iloc[0],\n",
    "        'area': group['area'].iloc[0],\n",
    "        'lon': unknown_coords[:, 0],\n",
    "        'lat': unknown_coords[:, 1],\n",
    "        'fire': group['fire'].iloc[0],\n",
    "         feature_name: interpolated_values  # 使用特性名称作为列名\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d21d1d-4ebc-4f39-9327-ba1ef73d5d45",
   "metadata": {},
   "source": [
    "火点数据集处理\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   "id": "98654812-3be2-491e-b429-399977f5558c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "fire = pd.read_excel(r'E:\\dataset\\fire2010-2017.xls')\n",
    "fire['fire'] = 1\n",
    "# 时间序列扩充\n",
    "new_rows_list = []\n",
    "\n",
    "# 遍历所有唯一的火灾日期\n",
    "for fire_date in fire['图像日期'].unique():\n",
    "    fire_rows = fire[fire['图像日期'] == fire_date]\n",
    "    \n",
    "    # 检查前两天和后一天的窗口\n",
    "    for offset in [-2, -1, 1]:\n",
    "        new_fire_date = pd.Timestamp(fire_date) + timedelta(days=offset)\n",
    "        \n",
    "        # 检查新日期是否已存在数据\n",
    "        existing_rows = fire[fire['图像日期'] == new_fire_date]\n",
    "        \n",
    "        if existing_rows.empty:  # 如果不存在数据，则创建新行\n",
    "            new_fire_rows = fire_rows.copy()\n",
    "            new_fire_rows['图像日期'] = new_fire_date\n",
    "            new_fire_rows['fire'] = 0\n",
    "            new_rows_list.append(new_fire_rows)\n",
    "        else:  # 如果存在数据，则使用原有数据\n",
    "            new_rows_list.append(existing_rows)\n",
    "\n",
    "# 使用pandas.concat合并所有新行\n",
    "new_rows = pd.concat(new_rows_list, ignore_index=True)\n",
    "\n",
    "extended_fire_data = pd.concat([fire, new_rows], ignore_index=True).drop_duplicates()"
=======
    "fire = pd.read_excel(r'/Users/yanyuchen/数据存放/森林火险/fire2010-2017.xls')"
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   "id": "99c31cf3-0990-4ee7-9463-88dc92d42f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provinces = ['辽宁省', '黑龙江省', '吉林省','云南省','四川省','贵州省']\n",
<<<<<<< HEAD
    "fire = extended_fire_data[extended_fire_data['地区'].isin(provinces)].copy()\n",
    "\n",
    "name_mapping = {\n",
    "    '地区': 'area',\n",
    "    '图像日期': 'time',\n",
    "    '东经': 'lon',\n",
    "    '北纬': 'lat',\n",
    "    'fire': 'fire'\n",
=======
    "fire = fire[fire['地区'].isin(provinces)]\n",
    "name = {'地区':'area',\n",
    "        '图像日期':'time',\n",
    "        '东经':'lon',\n",
    "        '北纬':'lat'\n",
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
    "}\n",
    "fire.rename(columns=name_mapping, inplace=True)\n",
    "\n",
    "# 转换时间列并添加时间特征\n",
    "fire['time'] = pd.to_datetime(fire['time'])\n",
    "fire['year'] = fire['time'].dt.year\n",
    "fire['month'] = fire['time'].dt.month\n",
    "fire['day'] = fire['time'].dt.day\n",
    "fire['hour'] = fire['time'].dt.hour\n",
    "fire['date'] = fire['time'].dt.date\n",
    "fire['date'] = pd.to_datetime(fire['date'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 7,
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   "id": "f5ecafb9-a96b-40ab-982f-2b01cfa2f8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>fire</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>贵州省</td>\n",
       "      <td>2010-01-03 14:13:00</td>\n",
       "      <td>107.99</td>\n",
       "      <td>28.37</td>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
=======
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>贵州省</td>\n",
       "      <td>2010-01-03 14:13:00</td>\n",
       "      <td>106.37</td>\n",
       "      <td>26.29</td>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
=======
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>贵州省</td>\n",
       "      <td>2010-01-03 14:13:00</td>\n",
       "      <td>106.41</td>\n",
       "      <td>27.32</td>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
=======
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>贵州省</td>\n",
       "      <td>2010-01-03 14:13:00</td>\n",
       "      <td>105.37</td>\n",
       "      <td>26.66</td>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
=======
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>贵州省</td>\n",
       "      <td>2010-01-03 16:37:00</td>\n",
       "      <td>107.97</td>\n",
       "      <td>28.33</td>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
=======
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2010-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "   area                time     lon    lat  fire  year  month  day  hour  \\\n",
       "4   贵州省 2010-01-03 14:13:00  107.99  28.37     1  2010      1    3    14   \n",
       "5   贵州省 2010-01-03 14:13:00  106.37  26.29     1  2010      1    3    14   \n",
       "6   贵州省 2010-01-03 14:13:00  106.41  27.32     1  2010      1    3    14   \n",
       "7   贵州省 2010-01-03 14:13:00  105.37  26.66     1  2010      1    3    14   \n",
       "10  贵州省 2010-01-03 16:37:00  107.97  28.33     1  2010      1    3    16   \n",
       "\n",
       "         date  \n",
       "4  2010-01-03  \n",
       "5  2010-01-03  \n",
       "6  2010-01-03  \n",
       "7  2010-01-03  \n",
       "10 2010-01-03  "
      ]
     },
     "execution_count": 6,
=======
       "   area                time     lon    lat  year  month  day  hour       date\n",
       "4   贵州省 2010-01-03 14:13:00  107.99  28.37  2010      1    3    14 2010-01-03\n",
       "5   贵州省 2010-01-03 14:13:00  106.37  26.29  2010      1    3    14 2010-01-03\n",
       "6   贵州省 2010-01-03 14:13:00  106.41  27.32  2010      1    3    14 2010-01-03\n",
       "7   贵州省 2010-01-03 14:13:00  105.37  26.66  2010      1    3    14 2010-01-03\n",
       "10  贵州省 2010-01-03 16:37:00  107.97  28.33  2010      1    3    16 2010-01-03"
      ]
     },
     "execution_count": 7,
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ee9cf-7739-44d4-9b99-bdaea25c6486",
   "metadata": {
    "tags": []
   },
   "source": [
    "站点数据读取\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 8,
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   "id": "248064ae-66e1-4047-8e30-45e10d843f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sta = pd.read_csv('/Users/yanyuchen/数据存放/森林火险/dataset.csv')\n",
    "sta['date'] = pd.to_datetime(sta[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31031c-3d7c-443b-9b5c-61f7912d297f",
   "metadata": {},
   "source": [
    "时间匹配"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 9,
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   "id": "7f1ad33e-ae11-43b3-9068-5fcfaf6d6c18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 397. MiB for an array with shape (1, 52009104) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43msta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfire\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:124\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:775\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    773\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 775\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:766\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    764\u001b[0m left\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m llabels\n\u001b[0;32m    765\u001b[0m right\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m rlabels\n\u001b[1;32m--> 766\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\.conda\\envs\\lab\\lib\\site-packages\\pandas\\core\\internals\\concat.py:212\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    210\u001b[0m values \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m--> 212\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 397. MiB for an array with shape (1, 52009104) and data type object"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "merged_data = pd.merge(sta, fire, left_on='date', right_on='date', how='inner')"
=======
    "merged_data = pd.merge(sta, fire, left_on='date', right_on='date', how='inner')\n",
    "#merged_data.to_csv('111.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95937b8-97dc-4a42-a8b5-50b39d340744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merged_data.head(100).to_csv('100.csv')"
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db33ef-01d0-4d85-ae0d-71702072d795",
   "metadata": {},
   "source": [
    "插值到火点（IDW）"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   "id": "ed35c060-84ff-4d25-86a6-f8e08274b49f",
   "metadata": {
    "tags": []
   },
<<<<<<< HEAD
   "outputs": [],
   "source": [
    "#要插值的要素\n",
    "# 'Alti', 'TEM_Max', 'TEM_Min', \n",
    "#                 'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max',  \n",
    "#                 'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'p', \n",
    "#                 'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI',\n",
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sta', 'Alti', 'year_x', 'month_x', 'day_x', 'TEM_Max', 'TEM_Min', 'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max', 'lon_x', 'lat_x', 'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'ic', 'p', 'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI', 'date', 'area', 'time', 'lon_y', 'lat_y', 'year_y', 'month_y', 'day_y', 'hour']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>area</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>TEM_Max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>贵州省</td>\n",
       "      <td>107.99</td>\n",
       "      <td>28.37</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>贵州省</td>\n",
       "      <td>106.37</td>\n",
       "      <td>26.29</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>贵州省</td>\n",
       "      <td>106.41</td>\n",
       "      <td>27.32</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>贵州省</td>\n",
       "      <td>105.37</td>\n",
       "      <td>26.66</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>贵州省</td>\n",
       "      <td>107.97</td>\n",
       "      <td>28.33</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  year  month  day area     lon    lat  TEM_Max\n",
       "0 2010-01-03  2010      1    3  贵州省  107.99  28.37     16.0\n",
       "1 2010-01-03  2010      1    3  贵州省  106.37  26.29     15.6\n",
       "2 2010-01-03  2010      1    3  贵州省  106.41  27.32     16.3\n",
       "3 2010-01-03  2010      1    3  贵州省  105.37  26.66     21.5\n",
       "4 2010-01-03  2010      1    3  贵州省  107.97  28.33     16.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#要插值的要素\n",
    "# merged_data = pd.read_csv('111.csv')\n",
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
    "column_names_list = merged_data.columns.tolist()\n",
    "print(column_names_list)\n",
    "column_names = [ 'Alti', 'TEM_Max', 'TEM_Min', \n",
    "                'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max',  \n",
    "                'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'p', \n",
    "                'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI','ic'\n",
    "               \n",
    "                ]\n",
    "\n",
    "# 初始化最终插值结果的DataFrame\n",
    "final_interpolated_results = None\n",
    "\n",
    "# 循环遍历每个要素，并执行插值\n",
    "for column_name in column_names:\n",
    "    # 对当前要素执行插值\n",
    "    interpolated_results = merged_data.groupby('date').apply(lambda group: perform_idw(group, column_name))\n",
    "    # 重置索引\n",
    "    interpolated_results.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 将插值结果合并到最终结果DataFrame\n",
    "    if final_interpolated_results is None:\n",
    "        final_interpolated_results = interpolated_results\n",
    "    else:\n",
    "        final_interpolated_results = final_interpolated_results.merge(interpolated_results, on=['date', 'lon', 'lat','year',\n",
    "                                                                                               'month','day','area','fire'])\n",
    "final_interpolated_results.to_csv('fire_point_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c6a35-611e-4dad-b8d6-e5ef75f2d12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "e3ca9ba5-e835-4ea5-a190-cb5de15664a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4524e4-431a-4752-bc18-f7e472d27ede",
=======
   "id": "12b17e09-0304-4f50-96c7-51224774ca5a",
>>>>>>> 32e092b5b09b17733190c1a3ab0e1a7d3596c183
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
