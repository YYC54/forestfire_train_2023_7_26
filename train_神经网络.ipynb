{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7f26e08-b213-433b-a10f-3691c498a5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from tqdm import tqdm\n",
    "# import meteva as mem\n",
    "# from meteva.method import pc\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from scipy.stats import pointbiserialr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d988662-f05f-4992-94f8-32cecb92375b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch == 100:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "627c30cf-6f93-4b21-8cff-de4fdeca9448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mix_feature(data):\n",
    "    # Selecting numerical features for interaction term creation\n",
    "    numerical_features = data.select_dtypes(include=['float64', 'int64']).drop(columns=['date', 'year', 'month', 'day', 'fire', 'lon', 'lat'])\n",
    "\n",
    "    # Creating interaction terms using PolynomialFeatures\n",
    "    polynomial_features = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    interaction_features = polynomial_features.fit_transform(numerical_features)\n",
    "\n",
    "    # Creating a DataFrame to hold the new interaction features\n",
    "    interaction_features_df = pd.DataFrame(interaction_features)\n",
    "\n",
    "    # Rename interaction features to ensure uniqueness\n",
    "    new_feature_names = [f'feature_{i}' for i in range(interaction_features_df.shape[1])]\n",
    "    interaction_features_df.columns = new_feature_names\n",
    "\n",
    "    # Merging the interaction features with the original dataset\n",
    "    data_with_interactions = pd.concat([data, interaction_features_df], axis=1)\n",
    "    return data_with_interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c70da7c5-d028-4f9f-abaa-661470352343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_features(df,thus):\n",
    "    selected_features = []\n",
    "    \n",
    "    # Loop through each feature column to calculate the Point-Biserial Correlation Coefficient\n",
    "    for column in df.columns:\n",
    "        if column not in ['fire', 'date', 'year', 'month', 'day', 'lon', 'lat']:\n",
    "            coeff, _ = pointbiserialr(df[column], df['fire'])\n",
    "            if abs(coeff) >= thus:\n",
    "                selected_features.append(column)\n",
    "    \n",
    "    print(f'Features with Point-Biserial Correlation Coefficient > {thus}: {selected_features}')\n",
    "    \n",
    "    # Combine selected features with other necessary columns\n",
    "    final_features = ['fire', 'date', 'year', 'month', 'day', 'lon', 'lat'] + selected_features\n",
    "    \n",
    "    return final_features\n",
    "# def select_features(df, threshold):\n",
    "#     \"\"\"\n",
    "#     Select features based on Mutual Information.\n",
    "    \n",
    "#     Parameters:\n",
    "#         df (DataFrame): The input data frame containing both features and target variable.\n",
    "#         threshold (float): The mutual information threshold for feature selection.\n",
    "    \n",
    "#     Returns:\n",
    "#         list: The names of selected features.\n",
    "#     \"\"\"\n",
    "#     # Filter out columns that should not be used for mutual information calculation\n",
    "#     feature_columns = [col for col in df.columns if col not in ['fire', 'date', 'year', 'month', 'day', 'lon', 'lat']]\n",
    "    \n",
    "#     # Calculate Mutual Information scores\n",
    "#     mutual_info_scores = mutual_info_classif(df[feature_columns], df['fire'])\n",
    "    \n",
    "#     # Select features based on the threshold\n",
    "#     selected_features = [feature_columns[i] for i in range(len(feature_columns)) if mutual_info_scores[i] >= threshold]\n",
    "    \n",
    "#     print(f'Features with Mutual Information >= {threshold}: {selected_features}')\n",
    "    \n",
    "#     # Combine selected features with other necessary columns\n",
    "#     final_features = ['fire', 'date', 'year', 'month', 'day', 'lon', 'lat'] + selected_features\n",
    "    \n",
    "#     return final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56ecddd0-52a1-4919-befa-3f627e6d0070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_outlier(df,feats):\n",
    "    _ = df[feats[0:]]\n",
    "    # 1. 计算每个气象要素的平均值和标准差\n",
    "    mean_values = _.mean()\n",
    "    std_values = _.std()\n",
    "    # 2. 根据三倍标准差法，设定异常值的阈值\n",
    "    threshold = 3 * std_values\n",
    "    # 3. 遍历每个气象要素的数值，将超过设定阈值的值标记为异常值\n",
    "    is_outlier = (_ > mean_values + threshold) | (_ < mean_values - threshold)\n",
    "    # 4. 对于标记为异常值的数据，可以根据需要选择删除、替换或进行插补处理\n",
    "    # 假设你选择删除异常值\n",
    "    df = df[~is_outlier.any(axis=1)]\n",
    "#     df = df.query('sw_max1<20 and sw_max2<20')\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37333280-ec53-4160-8a12-ef27171d6988",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire\n",
      "1    4531\n",
      "0    3253\n",
      "Name: count, dtype: int64\n",
      "Features with Point-Biserial Correlation Coefficient > 0.1: ['Alti', 'TEM_Max', 'TEM_Min', 'RHU_Min', 'FFDI', 'area_黑龙江省', 'feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_23', 'feature_25', 'feature_26', 'feature_28', 'feature_30', 'feature_47', 'feature_49', 'feature_51', 'feature_53', 'feature_58', 'feature_70', 'feature_73', 'feature_75', 'feature_87', 'feature_92', 'feature_96', 'feature_133', 'feature_170']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('fire_point_data.csv')\n",
    "fire_count = data['fire'].value_counts()\n",
    "print(fire_count)\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "scaler = StandardScaler()\n",
    "data['date'] = scaler.fit_transform(data['date'].values.reshape(-1, 1))\n",
    "\n",
    "#data = data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# 对分类特征进行独热编码\n",
    "data = pd.get_dummies(data, columns=['area'])\n",
    "data = mix_feature(data)\n",
    "feats_name = select_features(data, 0.1)\n",
    "data = process_outlier(data,feats_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "520bee93-7eba-4c45-8f7a-0c1f95430466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire\n",
      "1    3799\n",
      "0    2576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data = data[data['year']!=2017]\n",
    "pred_data = data[data['year']==2017]\n",
    "fire_count = train_data['fire'].value_counts()\n",
    "print(fire_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0888db82-5839-48c3-be82-3d6c67cc9111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire\n",
      "1    3799\n",
      "0    2576\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# train_data = data.dropna()\n",
    "fire_count = train_data['fire'].value_counts()\n",
    "print(fire_count)\n",
    "# 定义特征和目标变量\n",
    "x = train_data.drop('fire', axis=1)\n",
    "y = train_data['fire']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 特征标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 构建神经网络模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d8e2fe4-83de-4443-b1f3-c42bda414b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "128/128 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9897 - val_loss: 0.2745 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9890 - val_loss: 0.2619 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9895 - val_loss: 0.2837 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9843 - val_loss: 0.2510 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9924 - val_loss: 0.2481 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9924 - val_loss: 0.2515 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9944 - val_loss: 0.2531 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9941 - val_loss: 0.2531 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.2471 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 0.2591 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.2477 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.2697 - val_accuracy: 0.9324 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9850 - val_loss: 0.2776 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9885 - val_loss: 0.2462 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9885 - val_loss: 0.2636 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9919 - val_loss: 0.2721 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9939 - val_loss: 0.2894 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9848 - val_loss: 0.2973 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9880 - val_loss: 0.2516 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9922 - val_loss: 0.2761 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9946 - val_loss: 0.2817 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0256 - accuracy: 0.9949 - val_loss: 0.2809 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.9877 - val_loss: 0.3162 - val_accuracy: 0.9255 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9926 - val_loss: 0.2645 - val_accuracy: 0.9353 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9929 - val_loss: 0.2610 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.2687 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9944 - val_loss: 0.2733 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9941 - val_loss: 0.2786 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.3215 - val_accuracy: 0.9304 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.9826 - val_loss: 0.2654 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.2627 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9882 - val_loss: 0.2828 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9917 - val_loss: 0.2423 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.2620 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9936 - val_loss: 0.2677 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9877 - val_loss: 0.2762 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.2563 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9922 - val_loss: 0.2828 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9885 - val_loss: 0.2806 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.2811 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9895 - val_loss: 0.2528 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9929 - val_loss: 0.2534 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9941 - val_loss: 0.2615 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.2642 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.2629 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9953 - val_loss: 0.2591 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.2562 - val_accuracy: 0.9510 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.2633 - val_accuracy: 0.9480 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9953 - val_loss: 0.2663 - val_accuracy: 0.9480 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.2697 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.3002 - val_accuracy: 0.9284 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9850 - val_loss: 0.2617 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 0.3368 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.2514 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.2842 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 0.2645 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9926 - val_loss: 0.2978 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9934 - val_loss: 0.2701 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.2843 - val_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9895 - val_loss: 0.2566 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.2692 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.2679 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.2828 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.2786 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9914 - val_loss: 0.2899 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9909 - val_loss: 0.2677 - val_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.2702 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 0.9951 - val_loss: 0.2725 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.2796 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 0.9931 - val_loss: 0.2948 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9868 - val_loss: 0.2461 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.2580 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.2728 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.2744 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9944 - val_loss: 0.2866 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 0.2870 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.2743 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9919 - val_loss: 0.2819 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.2779 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9850 - val_loss: 0.2491 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 0.2706 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9902 - val_loss: 0.2538 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9924 - val_loss: 0.2772 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.2788 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.2817 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.2847 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 0.9956 - val_loss: 0.2893 - val_accuracy: 0.9461 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.3004 - val_accuracy: 0.9451 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.3124 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 0.9897 - val_loss: 0.2636 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9895 - val_loss: 0.2963 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9931 - val_loss: 0.2990 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9926 - val_loss: 0.2796 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.2786 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.2996 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.3294 - val_accuracy: 0.9275 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 0.2617 - val_accuracy: 0.9441 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.2770 - val_accuracy: 0.9422 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.2821 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.2986 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.2950 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.2940 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.2932 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.2933 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9956 - val_loss: 0.2947 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.2960 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9958 - val_loss: 0.2971 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.2984 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.2993 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.3004 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.3014 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 0.9966 - val_loss: 0.3022 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.3033 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.3034 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 0.3048 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.3053 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.3059 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.3068 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.3076 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.3085 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.3094 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.3106 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.3103 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.3108 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.3121 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.3131 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.3136 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.3143 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.3155 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.3158 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.3164 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.3169 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3181 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3187 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3196 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3196 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3203 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.3210 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3222 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.3225 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.3227 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3240 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3253 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3255 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3271 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3276 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9963 - val_loss: 0.3282 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.3261 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9963 - val_loss: 0.3281 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.3271 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "128/128 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.3282 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.3288 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.3289 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.3295 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.3302 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.3314 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.3328 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.3329 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.3342 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.3347 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3355 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3357 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.3363 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.3371 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.3354 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9971 - val_loss: 0.3355 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.3353 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.3364 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.3365 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.3366 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3379 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3379 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.3387 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3379 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3385 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3398 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3407 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.3403 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.3413 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.3449 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 0.3449 - val_accuracy: 0.9382 - lr: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.3426 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.3425 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.3436 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.3435 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.3430 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.3431 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.3434 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.3434 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.3428 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.3441 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.3437 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.3443 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.3449 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.3457 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9968 - val_loss: 0.3453 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.3456 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9973 - val_loss: 0.3452 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.3453 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.3473 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.3473 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.3466 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 0.3475 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9973 - val_loss: 0.3468 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.3437 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9973 - val_loss: 0.3443 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3407 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.3413 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3415 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3461 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3424 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.3437 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.3420 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3430 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3426 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3422 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.3393 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.3408 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.3425 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.3412 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3432 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9966 - val_loss: 0.3467 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.3488 - val_accuracy: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.3487 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9968 - val_loss: 0.3415 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.3427 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.3408 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.3415 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.3443 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9973 - val_loss: 0.3419 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.3405 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9968 - val_loss: 0.3435 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.3456 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.3468 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.3423 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.3422 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.3402 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3405 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.3412 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3431 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.3424 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 242/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3402 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 243/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3421 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 244/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3407 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 245/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3412 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 246/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3393 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 247/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3423 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 248/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3410 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 249/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3441 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 250/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3410 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 251/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3439 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 252/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.3414 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 253/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3427 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 254/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3406 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 255/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3415 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 256/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9975 - val_loss: 0.3418 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 257/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.3427 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 258/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3426 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 259/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3416 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 260/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3419 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 261/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3404 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 262/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3431 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 263/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3441 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 264/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3433 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 265/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.3399 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 266/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.3423 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 267/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.3434 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 268/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.3431 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 269/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.3442 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 270/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9975 - val_loss: 0.3440 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 271/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9973 - val_loss: 0.3437 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 272/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.3357 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 273/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 0.3448 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 274/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.3442 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 275/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.3414 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 276/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3417 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 277/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3412 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 278/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3408 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 279/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3407 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 280/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3402 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 281/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3409 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 282/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3409 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 283/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3407 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 284/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3404 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 285/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3398 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 286/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3404 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 287/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3393 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 288/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3387 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 289/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3391 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 290/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3396 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 291/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.3387 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 292/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3399 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 293/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3393 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 294/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3385 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 295/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3384 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 296/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3378 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 297/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3371 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 298/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.3338 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 299/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.3358 - val_accuracy: 0.9441 - lr: 1.0000e-04\n",
      "Epoch 300/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9975 - val_loss: 0.3445 - val_accuracy: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 301/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 0.9961 - val_loss: 0.3365 - val_accuracy: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 302/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9963 - val_loss: 0.3340 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 303/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.3325 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 304/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.3326 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 305/1000\n",
      "128/128 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.3328 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 306/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.3329 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "Epoch 307/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.3335 - val_accuracy: 0.9431 - lr: 1.0000e-04\n",
      "40/40 [==============================] - 0s 888us/step - loss: 0.4634 - accuracy: 0.9294\n",
      "Test Loss: 0.46\n",
      "Mean Absolute Error: 0.929411768913269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 创建EarlyStopping回调\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=100, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# 创建 LearningRateScheduler 回调\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "# 将 lr_scheduler 添加到回调列表中\n",
    "callbacks = [early_stopping, lr_scheduler]\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "# 编译模型\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "# 模型评估\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss: {:.2f}\".format(loss))\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "49bdb715-cad1-4e45-8da0-8a7cffeb75d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制训练损失和验证损失\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and accuracy')\n",
    "path = 'acc.png'\n",
    "plt.savefig(path, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cb3836-519f-4291-996d-0c9008213932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-lab",
   "language": "python",
   "name": "ai-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
