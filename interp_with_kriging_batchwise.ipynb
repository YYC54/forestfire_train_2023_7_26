{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c11c9a4-769a-486d-9f30-37adfb64cf81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "from pandas.errors import DtypeWarning\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "warnings.simplefilter(action='ignore', category=DtypeWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3814b68d-36c0-464a-8c36-b03422e1481f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kriging_interpolation(known_coords, known_values, unknown_coords):\n",
    "    # Extract the latitude and longitude from the known coordinates\n",
    "    lons = known_coords[:, 0]\n",
    "    lats = known_coords[:, 1]\n",
    "\n",
    "    # Create an OrdinaryKriging object\n",
    "    OK = OrdinaryKriging(\n",
    "        lons, lats, known_values, variogram_model='linear',\n",
    "        verbose=False, enable_plotting=False\n",
    "    )\n",
    "\n",
    "    # Extract the latitude and longitude for the unknown coordinates\n",
    "    unknown_lons = unknown_coords[:, 0]\n",
    "    unknown_lats = unknown_coords[:, 1]\n",
    "\n",
    "    # Perform the Kriging interpolation\n",
    "    z, ss = OK.execute('grid', unknown_lons, unknown_lats)\n",
    "\n",
    "    # Return the interpolated values\n",
    "    return z.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa14f0cb-5f5e-4810-9882-d4518170e0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def perform_kriging_batchwise(group, feature_name, batch_size=100):\n",
    "    results = []\n",
    "    if feature_name =='ic':\n",
    "        group[feature_name] = pd.to_numeric(group[feature_name], errors='coerce')\n",
    "\n",
    "    known_coords = group[['lon_x', 'lat_x']].values  # Known coordinates (stations)\n",
    "    known_values = group[feature_name].values        # Known values, using the passed feature name\n",
    "    known_values = known_values.astype(float)\n",
    "    \n",
    "    # Split the unknown coordinates into batches\n",
    "    unknown_coords = group[['lon_y', 'lat_y']].drop_duplicates().values  # Unknown coordinates (fire points)\n",
    "    total_points = len(unknown_coords)\n",
    "    \n",
    "    for i in range(0, total_points, batch_size):\n",
    "        batch_coords = unknown_coords[i:i+batch_size]\n",
    "        interpolated_values = kriging_interpolation(known_coords, known_values, batch_coords)  # Perform Kriging interpolation\n",
    "        \n",
    "        batch_result = pd.DataFrame({  # Return interpolation result\n",
    "            'date': group['date'].iloc[0],\n",
    "            'year': group['year_y'].iloc[0],\n",
    "            'month': group['month_y'].iloc[0],\n",
    "            'day': group['day_y'].iloc[0],\n",
    "            'area': group['area'].iloc[0],\n",
    "            'lon': batch_coords[:, 0],\n",
    "            'lat': batch_coords[:, 1],\n",
    "            'fire': group['fire'].iloc[0],\n",
    "            feature_name: interpolated_values  # Use feature name as the column name\n",
    "        })\n",
    "        results.append(batch_result)\n",
    "    \n",
    "    return pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d21d1d-4ebc-4f39-9327-ba1ef73d5d45",
   "metadata": {},
   "source": [
    "火点数据集处理\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98654812-3be2-491e-b429-399977f5558c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fire = pd.read_excel('fire2010-2017.xls')\n",
    "fire['fire'] = 1\n",
    "# 时间序列扩充\n",
    "new_rows_list = []\n",
    "\n",
    "# 遍历所有唯一的火灾日期\n",
    "for fire_date in fire['图像日期'].unique():\n",
    "    fire_rows = fire[fire['图像日期'] == fire_date]\n",
    "    \n",
    "    # 检查前两天和后一天的窗口\n",
    "    for offset in range(-10, 10):\n",
    "        new_fire_date = pd.Timestamp(fire_date) + timedelta(days=offset)\n",
    "        \n",
    "        # 检查新日期是否已存在数据\n",
    "        existing_rows = fire[fire['图像日期'] == new_fire_date]\n",
    "        \n",
    "        if existing_rows.empty:  # 如果不存在数据，则创建新行\n",
    "            new_fire_rows = fire_rows.copy()\n",
    "            new_fire_rows['图像日期'] = new_fire_date\n",
    "            new_fire_rows['fire'] = 0\n",
    "            new_rows_list.append(new_fire_rows)\n",
    "        else:  # 如果存在数据，则使用原有数据\n",
    "            new_rows_list.append(existing_rows)\n",
    "\n",
    "# 使用pandas.concat合并所有新行\n",
    "new_rows = pd.concat(new_rows_list, ignore_index=True)\n",
    "\n",
    "extended_fire_data = pd.concat([fire, new_rows], ignore_index=True).drop_duplicates()\n",
    "# extended_fire_data.to_csv(r'E:\\dataset\\fire2010-2017_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c31cf3-0990-4ee7-9463-88dc92d42f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provinces = ['辽宁省', '黑龙江省', '吉林省']\n",
    "fire = extended_fire_data[extended_fire_data['地区'].isin(provinces)].copy()\n",
    "\n",
    "name_mapping = {\n",
    "    '地区': 'area',\n",
    "    '图像日期': 'time',\n",
    "    '东经': 'lon',\n",
    "    '北纬': 'lat',\n",
    "    'fire': 'fire'\n",
    "}\n",
    "fire.rename(columns=name_mapping, inplace=True)\n",
    "\n",
    "# 转换时间列并添加时间特征\n",
    "fire['time'] = pd.to_datetime(fire['time'])\n",
    "fire['year'] = fire['time'].dt.year\n",
    "fire['month'] = fire['time'].dt.month\n",
    "fire['day'] = fire['time'].dt.day\n",
    "fire['hour'] = fire['time'].dt.hour\n",
    "fire['date'] = fire['time'].dt.date\n",
    "fire['date'] = pd.to_datetime(fire['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ecafb9-a96b-40ab-982f-2b01cfa2f8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>fire</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-03-10 12:41:00</td>\n",
       "      <td>120.1782</td>\n",
       "      <td>40.9771</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-03-30 10:18:00</td>\n",
       "      <td>122.3467</td>\n",
       "      <td>40.4534</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-03-30 11:23:00</td>\n",
       "      <td>122.3741</td>\n",
       "      <td>40.4504</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2010-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-04-01 13:07:00</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>41.4604</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2010-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-04-01 13:49:00</td>\n",
       "      <td>121.3935</td>\n",
       "      <td>41.4570</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2010-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area                time       lon      lat  fire  year  month  day  \\\n",
       "2164  辽宁省 2010-03-10 12:41:00  120.1782  40.9771     1  2010      3   10   \n",
       "2833  辽宁省 2010-03-30 10:18:00  122.3467  40.4534     1  2010      3   30   \n",
       "2834  辽宁省 2010-03-30 11:23:00  122.3741  40.4504     1  2010      3   30   \n",
       "2837  辽宁省 2010-04-01 13:07:00  121.3900  41.4604     1  2010      4    1   \n",
       "2838  辽宁省 2010-04-01 13:49:00  121.3935  41.4570     1  2010      4    1   \n",
       "\n",
       "      hour       date  \n",
       "2164    12 2010-03-10  \n",
       "2833    10 2010-03-30  \n",
       "2834    11 2010-03-30  \n",
       "2837    13 2010-04-01  \n",
       "2838    13 2010-04-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ee9cf-7739-44d4-9b99-bdaea25c6486",
   "metadata": {
    "tags": []
   },
   "source": [
    "站点数据读取\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248064ae-66e1-4047-8e30-45e10d843f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sta = pd.read_csv('dataset.csv')\n",
    "sta['date'] = pd.to_datetime(sta[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31031c-3d7c-443b-9b5c-61f7912d297f",
   "metadata": {},
   "source": [
    "时间匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1ad33e-ae11-43b3-9068-5fcfaf6d6c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = pd.merge(sta, fire, left_on='date', right_on='date', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db33ef-01d0-4d85-ae0d-71702072d795",
   "metadata": {},
   "source": [
    "插值到火点（IDW）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed35c060-84ff-4d25-86a6-f8e08274b49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sta', 'Alti', 'year_x', 'month_x', 'day_x', 'TEM_Max', 'TEM_Min', 'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max', 'lon_x', 'lat_x', 'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'ic', 'p', 'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI', 'date', 'area', 'time', 'lon_y', 'lat_y', 'fire', 'year_y', 'month_y', 'day_y', 'hour']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OrdinaryKriging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 循环遍历每个要素，并执行插值\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 对当前要素执行插值\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     interpolated_results \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mperform_kriging_batchwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# 重置索引\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     interpolated_results\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 循环遍历每个要素，并执行插值\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 对当前要素执行插值\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     interpolated_results \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m group: \u001b[43mperform_kriging_batchwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# 重置索引\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     interpolated_results\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36mperform_kriging_batchwise\u001b[0;34m(group, feature_name, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total_points, batch_size):\n\u001b[1;32m     15\u001b[0m     batch_coords \u001b[38;5;241m=\u001b[39m unknown_coords[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[0;32m---> 16\u001b[0m     interpolated_values \u001b[38;5;241m=\u001b[39m \u001b[43mkriging_interpolation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknown_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_coords\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Perform Kriging interpolation\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({  \u001b[38;5;66;03m# Return interpolation result\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear_y\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m         feature_name: interpolated_values  \u001b[38;5;66;03m# Use feature name as the column name\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     })\n\u001b[1;32m     29\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(batch_result)\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mkriging_interpolation\u001b[0;34m(known_coords, known_values, unknown_coords)\u001b[0m\n\u001b[1;32m      4\u001b[0m lats \u001b[38;5;241m=\u001b[39m known_coords[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create an OrdinaryKriging object\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m OK \u001b[38;5;241m=\u001b[39m \u001b[43mOrdinaryKriging\u001b[49m(\n\u001b[1;32m      8\u001b[0m     lons, lats, known_values, variogram_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, enable_plotting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Extract the latitude and longitude for the unknown coordinates\u001b[39;00m\n\u001b[1;32m     13\u001b[0m unknown_lons \u001b[38;5;241m=\u001b[39m unknown_coords[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OrdinaryKriging' is not defined"
     ]
    }
   ],
   "source": [
    "#要插值的要素\n",
    "# 'Alti', 'TEM_Max', 'TEM_Min', \n",
    "#                 'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max',  \n",
    "#                 'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'p', \n",
    "#                 'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI',\n",
    "column_names_list = merged_data.columns.tolist()\n",
    "print(column_names_list)\n",
    "column_names = [ 'Alti', 'TEM_Max', 'TEM_Min', \n",
    "                'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max',  \n",
    "                'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'p', \n",
    "                'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI','ic'\n",
    "               \n",
    "                ]\n",
    "\n",
    "# 初始化最终插值结果的DataFrame\n",
    "final_interpolated_results = None\n",
    "\n",
    "# 循环遍历每个要素，并执行插值\n",
    "for column_name in column_names:\n",
    "    # 对当前要素执行插值\n",
    "    interpolated_results = merged_data.groupby('date').apply(lambda group: perform_kriging_batchwise(group, column_name))\n",
    "    # 重置索引\n",
    "    interpolated_results.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 将插值结果合并到最终结果DataFrame\n",
    "    if final_interpolated_results is None:\n",
    "        final_interpolated_results = interpolated_results\n",
    "    else:\n",
    "        final_interpolated_results = final_interpolated_results.merge(interpolated_results, on=['date', 'lon', 'lat','year',\n",
    "                                                                                               'month','day','area','fire'])\n",
    "final_interpolated_results.to_csv('fire_point_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c6a35-611e-4dad-b8d6-e5ef75f2d12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca9ba5-e835-4ea5-a190-cb5de15664a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4524e4-431a-4752-bc18-f7e472d27ede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily",
   "language": "python",
   "name": "daily"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
