{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c11c9a4-769a-486d-9f30-37adfb64cf81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from scipy.spatial.distance import cdist\n",
    "import warnings\n",
    "from pandas.errors import DtypeWarning\n",
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "warnings.simplefilter(action='ignore', category=DtypeWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3814b68d-36c0-464a-8c36-b03422e1481f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kriging_interpolation(known_coords, known_values, unknown_coords):\n",
    "    # Extract the latitude and longitude from the known coordinates\n",
    "    lons = known_coords[:, 0]\n",
    "    lats = known_coords[:, 1]\n",
    "\n",
    "    # Create an OrdinaryKriging object\n",
    "    OK = OrdinaryKriging(\n",
    "        lons, lats, known_values, variogram_model='linear',\n",
    "        verbose=False, enable_plotting=False\n",
    "    )\n",
    "\n",
    "    # Extract the latitude and longitude for the unknown coordinates\n",
    "    unknown_lons = unknown_coords[:, 0]\n",
    "    unknown_lats = unknown_coords[:, 1]\n",
    "    print(len(unknown_lons))\n",
    "    print(len(unknown_lats))\n",
    "    # Perform the Kriging interpolation\n",
    "    z, ss = OK.execute('grid', unknown_lons, unknown_lats)\n",
    "    # Return the interpolated values\n",
    "    return z.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa14f0cb-5f5e-4810-9882-d4518170e0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def perform_kriging_batchwise(group, feature_name, batch_size=100):\n",
    "    results = []\n",
    "    if feature_name =='ic':\n",
    "        group[feature_name] = pd.to_numeric(group[feature_name], errors='coerce')\n",
    "\n",
    "    known_coords = group[['lon_x', 'lat_x']].values  # Known coordinates (stations)\n",
    "    known_values = group[feature_name].values        # Known values, using the passed feature name\n",
    "    known_values = known_values.astype(float)\n",
    "    \n",
    "    # Split the unknown coordinates into batches\n",
    "    unknown_coords = group[['lon_y', 'lat_y']].drop_duplicates().values  # Unknown coordinates (fire points)\n",
    "    print(unknown_coords)\n",
    "    total_points = len(unknown_coords)\n",
    "    \n",
    "    for i in range(0, total_points, batch_size):\n",
    "        batch_coords = unknown_coords[i:i+batch_size]\n",
    "        n = len(batch_coords)\n",
    "        interpolated_values = kriging_interpolation(known_coords, known_values, batch_coords)  # Perform Kriging interpolation\n",
    "        # print(batch_coords)\n",
    "        # print(interpolated_values)\n",
    "        # # interpolated_values = interpolated_values[:n]\n",
    "        # print(\"Length of batch_coords:\", len(batch_coords))\n",
    "        # print(\"Length of interpolated_values:\", len(interpolated_values))\n",
    "\n",
    "        batch_result = pd.DataFrame({  # Return interpolation result\n",
    "            'date': group['date'].iloc[0],\n",
    "            'year': group['year_y'].iloc[0],\n",
    "            'month': group['month_y'].iloc[0],\n",
    "            'day': group['day_y'].iloc[0],\n",
    "            'area': group['area'].iloc[0],\n",
    "            'lon': batch_coords[:, 0],\n",
    "            'lat': batch_coords[:, 1],\n",
    "            'fire': group['fire'].iloc[0],\n",
    "            feature_name: interpolated_values  # Use feature name as the column name\n",
    "        })\n",
    "        results.append(batch_result)\n",
    "    \n",
    "    return pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d21d1d-4ebc-4f39-9327-ba1ef73d5d45",
   "metadata": {},
   "source": [
    "火点数据集处理\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98654812-3be2-491e-b429-399977f5558c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fire = pd.read_excel('fire2010-2017.xls')\n",
    "fire['fire'] = 1\n",
    "# 时间序列扩充\n",
    "new_rows_list = []\n",
    "\n",
    "# 遍历所有唯一的火灾日期\n",
    "for fire_date in fire['图像日期'].unique():\n",
    "    fire_rows = fire[fire['图像日期'] == fire_date]\n",
    "    \n",
    "    # 检查前两天和后一天的窗口\n",
    "    for offset in range(-10, 10):\n",
    "        new_fire_date = pd.Timestamp(fire_date) + timedelta(days=offset)\n",
    "        \n",
    "        # 检查新日期是否已存在数据\n",
    "        existing_rows = fire[fire['图像日期'] == new_fire_date]\n",
    "        \n",
    "        if existing_rows.empty:  # 如果不存在数据，则创建新行\n",
    "            new_fire_rows = fire_rows.copy()\n",
    "            new_fire_rows['图像日期'] = new_fire_date\n",
    "            new_fire_rows['fire'] = 0\n",
    "            new_rows_list.append(new_fire_rows)\n",
    "        else:  # 如果存在数据，则使用原有数据\n",
    "            new_rows_list.append(existing_rows)\n",
    "\n",
    "# 使用pandas.concat合并所有新行\n",
    "new_rows = pd.concat(new_rows_list, ignore_index=True)\n",
    "\n",
    "extended_fire_data = pd.concat([fire, new_rows], ignore_index=True).drop_duplicates()\n",
    "# extended_fire_data.to_csv(r'E:\\dataset\\fire2010-2017_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c31cf3-0990-4ee7-9463-88dc92d42f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "provinces = ['辽宁省', '黑龙江省', '吉林省']\n",
    "fire = extended_fire_data[extended_fire_data['地区'].isin(provinces)].copy()\n",
    "\n",
    "name_mapping = {\n",
    "    '地区': 'area',\n",
    "    '图像日期': 'time',\n",
    "    '东经': 'lon',\n",
    "    '北纬': 'lat',\n",
    "    'fire': 'fire'\n",
    "}\n",
    "fire.rename(columns=name_mapping, inplace=True)\n",
    "\n",
    "# 转换时间列并添加时间特征\n",
    "fire['time'] = pd.to_datetime(fire['time'])\n",
    "fire['year'] = fire['time'].dt.year\n",
    "fire['month'] = fire['time'].dt.month\n",
    "fire['day'] = fire['time'].dt.day\n",
    "fire['hour'] = fire['time'].dt.hour\n",
    "fire['date'] = fire['time'].dt.date\n",
    "fire['date'] = pd.to_datetime(fire['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ecafb9-a96b-40ab-982f-2b01cfa2f8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>fire</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-03-10 12:41:00</td>\n",
       "      <td>120.1782</td>\n",
       "      <td>40.9771</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>2010-03-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-03-30 10:18:00</td>\n",
       "      <td>122.3467</td>\n",
       "      <td>40.4534</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>2010-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-03-30 11:23:00</td>\n",
       "      <td>122.3741</td>\n",
       "      <td>40.4504</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2010-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-04-01 13:07:00</td>\n",
       "      <td>121.3900</td>\n",
       "      <td>41.4604</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2010-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>辽宁省</td>\n",
       "      <td>2010-04-01 13:49:00</td>\n",
       "      <td>121.3935</td>\n",
       "      <td>41.4570</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2010-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     area                time       lon      lat  fire  year  month  day  \\\n",
       "2164  辽宁省 2010-03-10 12:41:00  120.1782  40.9771     1  2010      3   10   \n",
       "2833  辽宁省 2010-03-30 10:18:00  122.3467  40.4534     1  2010      3   30   \n",
       "2834  辽宁省 2010-03-30 11:23:00  122.3741  40.4504     1  2010      3   30   \n",
       "2837  辽宁省 2010-04-01 13:07:00  121.3900  41.4604     1  2010      4    1   \n",
       "2838  辽宁省 2010-04-01 13:49:00  121.3935  41.4570     1  2010      4    1   \n",
       "\n",
       "      hour       date  \n",
       "2164    12 2010-03-10  \n",
       "2833    10 2010-03-30  \n",
       "2834    11 2010-03-30  \n",
       "2837    13 2010-04-01  \n",
       "2838    13 2010-04-01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ee9cf-7739-44d4-9b99-bdaea25c6486",
   "metadata": {
    "tags": []
   },
   "source": [
    "站点数据读取\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248064ae-66e1-4047-8e30-45e10d843f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sta = pd.read_csv('dataset.csv')\n",
    "sta['date'] = pd.to_datetime(sta[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc31031c-3d7c-443b-9b5c-61f7912d297f",
   "metadata": {},
   "source": [
    "时间匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1ad33e-ae11-43b3-9068-5fcfaf6d6c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = pd.merge(sta, fire, left_on='date', right_on='date', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e97347e-7fe3-4f1b-a925-2352bfc06e88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sta   Alti  year_x  month_x  day_x  TEM_Max  TEM_Min  RHU_Min  \\\n",
      "0  50136  433.0    2010        2     28    -13.0    -40.8       23   \n",
      "1  50246  361.9    2010        2     28    -12.9    -37.0       27   \n",
      "2  50247  514.5    2010        2     28    -12.8    -38.5       24   \n",
      "3  50349  494.6    2010        2     28    -12.3    -33.0       27   \n",
      "4  50353  177.4    2010        2     28    -13.1    -28.7       30   \n",
      "\n",
      "   PRE_Time_2020  Snow_Depth  ...       date  area                time  \\\n",
      "0            0.0        29.0  ... 2010-02-28   辽宁省 2010-02-28 12:41:00   \n",
      "1            0.0        24.0  ... 2010-02-28   辽宁省 2010-02-28 12:41:00   \n",
      "2            0.0        20.0  ... 2010-02-28   辽宁省 2010-02-28 12:41:00   \n",
      "3            0.0        17.0  ... 2010-02-28   辽宁省 2010-02-28 12:41:00   \n",
      "4            0.0        16.0  ... 2010-02-28   辽宁省 2010-02-28 12:41:00   \n",
      "\n",
      "      lon_y    lat_y  fire  year_y  month_y  day_y  hour  \n",
      "0  120.1782  40.9771     0    2010        2     28    12  \n",
      "1  120.1782  40.9771     0    2010        2     28    12  \n",
      "2  120.1782  40.9771     0    2010        2     28    12  \n",
      "3  120.1782  40.9771     0    2010        2     28    12  \n",
      "4  120.1782  40.9771     0    2010        2     28    12  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db33ef-01d0-4d85-ae0d-71702072d795",
   "metadata": {},
   "source": [
    "插值到火点（kriging）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed35c060-84ff-4d25-86a6-f8e08274b49f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sta', 'Alti', 'year_x', 'month_x', 'day_x', 'TEM_Max', 'TEM_Min', 'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max', 'lon_x', 'lat_x', 'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'ic', 'p', 'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI', 'date', 'area', 'time', 'lon_y', 'lat_y', 'fire', 'year_y', 'month_y', 'day_y', 'hour']\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[120.1782  40.9771]]\n",
      "1\n",
      "1\n",
      "[[122.3467  40.4534]\n",
      " [122.3741  40.4504]]\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 循环遍历每个要素，并执行插值\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 对当前要素执行插值\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     interpolated_results \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mperform_kriging_batchwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# 重置索引\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     interpolated_results\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 循环遍历每个要素，并执行插值\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# 对当前要素执行插值\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     interpolated_results \u001b[38;5;241m=\u001b[39m merged_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m group: \u001b[43mperform_kriging_batchwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# 重置索引\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     interpolated_results\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mperform_kriging_batchwise\u001b[0;34m(group, feature_name, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m     interpolated_values \u001b[38;5;241m=\u001b[39m kriging_interpolation(known_coords, known_values, batch_coords)  \u001b[38;5;66;03m# Perform Kriging interpolation\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# print(batch_coords)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# print(interpolated_values)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# # interpolated_values = interpolated_values[:n]\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# print(\"Length of batch_coords:\", len(batch_coords))\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# print(\"Length of interpolated_values:\", len(interpolated_values))\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     batch_result \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Return interpolation result\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmonth_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mday\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mday_y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marea\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marea\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_coords\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfire\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfire\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolated_values\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use feature name as the column name\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(batch_result)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(results, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/daily/lib/python3.8/site-packages/pandas/core/internals/construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#要插值的要素\n",
    "# 'Alti', 'TEM_Max', 'TEM_Min', \n",
    "#                 'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max',  \n",
    "#                 'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'p', \n",
    "#                 'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI',\n",
    "column_names_list = merged_data.columns.tolist()\n",
    "print(column_names_list)\n",
    "column_names = [ 'Alti', 'TEM_Max', 'TEM_Min', \n",
    "                'RHU_Min', 'PRE_Time_2020', 'Snow_Depth', 'WIN_S_Max',  \n",
    "                'yth1', 'yth10', 'yth100', 'yth1000', 'kb', 'erc', 'sc', 'bi', 'p', \n",
    "                'FFMC', 'DMC', 'DC', 'FWI', 'ISI', 'BUI', 'DSR', 'FFDI','ic'\n",
    "               \n",
    "                ]\n",
    "\n",
    "# 初始化最终插值结果的DataFrame\n",
    "final_interpolated_results = None\n",
    "\n",
    "# 循环遍历每个要素，并执行插值\n",
    "for column_name in column_names:\n",
    "    # 对当前要素执行插值\n",
    "    interpolated_results = merged_data.groupby('date').apply(lambda group: perform_kriging_batchwise(group, column_name))\n",
    "    # 重置索引\n",
    "    interpolated_results.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 将插值结果合并到最终结果DataFrame\n",
    "    if final_interpolated_results is None:\n",
    "        final_interpolated_results = interpolated_results\n",
    "    else:\n",
    "        final_interpolated_results = final_interpolated_results.merge(interpolated_results, on=['date', 'lon', 'lat','year',\n",
    "                                                                                               'month','day','area','fire'])\n",
    "final_interpolated_results.to_csv('fire_point_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609d195-cd9e-4bbd-8605-07b882a69cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily",
   "language": "python",
   "name": "daily"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
